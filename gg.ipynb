{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: kaggle in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (5.29.4)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (65.5.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib opencv-python kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\princ\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\princ\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"archive.zip\"  # Update the path\n",
    "\n",
    "# Extract dataset\n",
    "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")\n",
    "\n",
    "print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        FILENAME  IDENTITY\n",
      "0  TEST_0001.jpg     KEVIN\n",
      "1  TEST_0002.jpg  CLOTAIRE\n",
      "2  TEST_0003.jpg      LENA\n",
      "3  TEST_0004.jpg     JULES\n",
      "4  TEST_0005.jpg   CHERPIN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "# Path to extracted dataset\n",
    "data_dir = pathlib.Path(\"dataset\")\n",
    "\n",
    "# Load labels (CSV file contains filename-image mappings)\n",
    "labels_file = os.path.join(data_dir, \"written_name_test_v2.csv\")\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# View first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size (adjust based on your model requirements)\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess an image\n",
    "def process_image(image_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    \"\"\"Loads an image, converts to grayscale, resizes, normalizes, and expands dimensions.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(image_path):  # Check if the file exists\n",
    "        raise FileNotFoundError(f\"❌ Image not found: {image_path}\")\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "    if img is None:  # Check if image loaded properly\n",
    "        raise ValueError(f\"⚠️ Error loading image: {image_path}\")\n",
    "\n",
    "    img = cv2.resize(img, img_size)  # Resize image\n",
    "    img = img / 255.0  # Normalize pixel values (0 to 1)\n",
    "    img = np.expand_dims(img, axis=-1)  # Add a channel dimension for CNNs\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image processed successfully! Shape: (32, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# ✅ Example Usage: Process a sample image\n",
    "sample_image_path = \"dataset/train_v2/train/TRAIN_00001.jpg\"  # Replace with an actual image path\n",
    "processed_img = process_image(sample_image_path)\n",
    "\n",
    "print(\"✅ Image processed successfully! Shape:\", processed_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330396/330396 [45:55<00:00, 119.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Loaded: (330396, 32, 128, 1), Labels: 330396\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Shows a progress bar\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_dir = \"dataset\"  # Replace with actual dataset path\n",
    "train_images_path = os.path.join(dataset_dir, \"train_v2/train\")\n",
    "train_csv_path = os.path.join(dataset_dir, \"written_name_train_v2.csv\")\n",
    "\n",
    "# Load CSV\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Remove missing or NaN values\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "# Define empty lists to store data\n",
    "X_train, y_train = [], []\n",
    "\n",
    "# ✅ Process all images in the dataset\n",
    "for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    filename = row[\"FILENAME\"]\n",
    "    label = row[\"IDENTITY\"]\n",
    "\n",
    "    image_path = os.path.join(train_images_path, filename)\n",
    "\n",
    "    # Check if file exists\n",
    "    if os.path.exists(image_path):\n",
    "        img = process_image(image_path)  # Apply preprocessing\n",
    "        X_train.append(img)\n",
    "        y_train.append(label)  # Keep the label (handwritten text)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {image_path}\")  # Debugging message\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"✅ Dataset Loaded: {X_train.shape}, Labels: {len(y_train)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Label Encoding ---\n",
    "# Create a mapping from characters to integers\n",
    "char_list = sorted(list(set(char for label in y_train for char in label)))\n",
    "char_to_num = {char: idx + 1 for idx, char in enumerate(char_list)}  # +1 for blank label\n",
    "num_to_char = {idx + 1: char for idx, char in enumerate(char_list)}\n",
    "\n",
    "# Add padding to labels\n",
    "max_label_len = max([len(label) for label in y_train])\n",
    "label_len = [len(label) for label in y_train]\n",
    "\n",
    "def encode_labels(labels, max_len, char_to_num):\n",
    "    encoded_labels = np.zeros((len(labels), max_len), dtype=np.float32)\n",
    "    for i, label in enumerate(labels):\n",
    "        encoded_label = [char_to_num.get(char, 0) for char in label]\n",
    "        encoded_labels[i, :len(encoded_label)] = encoded_label\n",
    "    return encoded_labels\n",
    "\n",
    "encoded_y_train = encode_labels(y_train, max_label_len, char_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Building ---\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "input_data = Input(shape=input_shape)\n",
    "\n",
    "conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_data)\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)\n",
    "conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv_3)\n",
    "pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_4)\n",
    "batch_norm_5 = tf.keras.layers.BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = tf.keras.layers.BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPooling2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "conv_7 = Conv2D(512, (2, 2), activation='relu')(pool_6)\n",
    "\n",
    "# Reshape for RNN\n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "\n",
    "# RNN\n",
    "blstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout=0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(256, return_sequences=True, dropout=0.2))(blstm_1)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(len(char_list) + 1, activation='softmax')(blstm_2)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=outputs)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy')\n",
    "\n",
    "# --- CTC Loss ---\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "ctc_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss) #Here ctc_model is defined.\n",
    "ctc_model.compile(optimizer=Adam(learning_rate=0.001), loss={'ctc': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare input for CTC ---\n",
    "input_length_train = np.ones(len(X_train)) * (IMG_WIDTH // 4 - 2)  # Adjust based on model architecture\n",
    "label_length_train = np.array([len(label) for label in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\princ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\legacy\\backend.py:666: The name tf.nn.ctc_loss is deprecated. Please use tf.compat.v1.nn.ctc_loss instead.\n",
      "\n",
      "\u001b[1m 157/4130\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:47\u001b[0m 2s/step - loss: 24.9025"
     ]
    }
   ],
   "source": [
    "# --- Training ---\n",
    "ctc_model.fit(\n",
    "    [X_train, encoded_y_train, input_length_train, label_length_train],\n",
    "    np.zeros(len(X_train)),\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    batch_size=64, # Adjust batch_size as needed\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
